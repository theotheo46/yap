{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект Определение стоимости автомобилей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сервис по продаже автомобилей с пробегом «Не бит, не крашен» разрабатывает приложение, чтобы привлечь новых клиентов. В нём можно будет узнать рыночную стоимость своего автомобиля. \n",
    "Постройте модель, которая умеет её определять. В вашем распоряжении данные о технических характеристиках, комплектации и ценах других автомобилей.\n",
    "Критерии, которые важны заказчику:\n",
    "- качество предсказания;\n",
    "- время обучения модели;\n",
    "- время предсказания модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Признаки\n",
    "- DateCrawled — дата скачивания анкеты из базы\n",
    "- VehicleType — тип автомобильного кузова\n",
    "- RegistrationYear — год регистрации автомобиля\n",
    "- Gearbox — тип коробки передач\n",
    "- Power — мощность (л. с.)\n",
    "- Model — модель автомобиля\n",
    "- Kilometer — пробег (км)\n",
    "- RegistrationMonth — месяц регистрации автомобиля\n",
    "- FuelType — тип топлива\n",
    "- Brand — марка автомобиля\n",
    "- Repaired — была машина в ремонте или нет\n",
    "- DateCreated — дата создания анкеты\n",
    "- NumberOfPictures — количество фотографий автомобиля\n",
    "- PostalCode — почтовый индекс владельца анкеты (пользователя)\n",
    "- LastSeen — дата последней активности пользователя\n",
    "#### Целевой признак\n",
    "- Price — цена (евро)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q catboost\n",
    "!pip install -q phik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'lightgbm[scikit-learn]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, precision_score, make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "from phik import phik_matrix\n",
    "from phik.report import plot_correlation_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "from sklearn.svm import SVC, SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n",
    "\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = pd.read_csv('https://code.s3.yandex.net/datasets/autos.csv')\n",
    "display(df_cars.head(5))\n",
    "df_cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По загруженным данным можно сделать следующие выводы:\n",
    "- размерность датасета 354369 х 16\n",
    "- датасет содержит как числовые так и категориальные типы данных. Кроме полей которые содержат дату и имеют тип object (DateCrawled, DateCreated, LastSeen), все остальные типы соответствуют своим данным. Типы колонок DateCrawled, DateCreated, LastSeen надо перобразовать в соответствующие типы (date или timestamp)\n",
    "- в некоторых колонках имеются пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Колонки DateCrawled, DateCreated, LastSeen приведены к типу datetime64\n",
    "- Остальные колонки типа object приведены к типу string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_str_col_list = df_cars.select_dtypes(exclude=np.number).columns\n",
    "df_cars[df_cars_str_col_list] = df_cars[df_cars_str_col_list].astype('string')\n",
    "\n",
    "df_cars['DateCrawled'] = pd.to_datetime(df_cars['DateCrawled'])\n",
    "df_cars['DateCreated'] = pd.to_datetime(df_cars['DateCreated'])\n",
    "df_cars['LastSeen'] = pd.to_datetime(df_cars['LastSeen'])\n",
    "\n",
    "df_cars.info()\n",
    "df_cars.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колонка NumberOfPictures содержит значения все равные 0. В связи с этим она признана неинформативной и удалена из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.describe()\n",
    "df_cars = df_cars.drop(['NumberOfPictures'], axis = 1)\n",
    "df_cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы предварительно обнаружить дубликаты, надо определить набор аттрибутов на которых надо определять эти дубликаты. Во первых, надо из общего числа аттрибутов убрать целевой признак Price, потом убрать те входные признаки, которые не будут участвовать в работе модели.\n",
    "На мой взгляд это такие служебные признаки как:\n",
    "- DateCrawled — дата скачивания анкеты из базы\n",
    "- DateCreated — дата создания анкеты\n",
    "- LastSeen — дата последней активности пользователя\n",
    "\n",
    "Обнаружено 34565 дубликатов для всех входных аттрибутов (исключая вышеперечисленные). Пока с ними ничего не буду делать, так как далее будет иметь место заполнение пропусков и я посмотрю на дубликаты после этой процедуры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_for_duplicates = [\"Price\", \"DateCrawled\", \"DateCreated\", \"LastSeen\"]\n",
    "print(f'Количество дубликатов: df_cars: {df_cars.duplicated(subset=df_cars.columns.difference(list_for_duplicates)).sum()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ананлиз данных (метод info()) показал, что пропуски имеют место только в категориальных колонках (кроме колонки Brand) и в связи с этим принято решение заполнить их в пайплайне SimpleImputer модой для соответствующего аттрибута. После этого еще раз провести проверку на дубликаты и уже после этого удалить имеющиеся дубликаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_list = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'Repaired']\n",
    "def display_value_count(df, col_list):\n",
    "    for c in col_list:\n",
    "        print(f\"------- {c} -------\")\n",
    "        display(df[c].value_counts(dropna = False))\n",
    "\n",
    "display_value_count(df_cars, cat_col_list)\n",
    "\n",
    "df_cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использую пайплайн для применения SimpleImputer на этапе предобработки данных. В пайплайне использую SimpleImputer  для замены NaN на моду для колонок из списка cat_col_list с категориальными признаками так как пропуски имеют место только для этих колонок.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = df_cars.replace({pd.NA: np.nan})\n",
    "df_cars_dtypes = df_cars.dtypes\n",
    "\n",
    "X = df_cars.drop(['Price'], axis=1)\n",
    "y = df_cars['Price']\n",
    "\n",
    "simple_imp_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            'simpleImputer_nan', \n",
    "            SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('simple_imp_pipeline', simple_imp_pipeline, X.columns)\n",
    "    ], \n",
    "    remainder='passthrough'\n",
    ") \n",
    "\n",
    "pipe_final = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', data_preprocessor)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_cars_arr = pipe_final.fit_transform(X)\n",
    "df_cars = pd.concat([pd.DataFrame(df_cars_arr, columns = X.columns),y], axis=1)\n",
    "for col in df_cars.columns:\n",
    "  df_cars[col] = df_cars[col].astype(df_cars_dtypes[col])\n",
    "display_value_count(df_cars, cat_col_list)\n",
    "df_cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После замены пропусков на моду еще раз проверил количество дубликатов и их число теперь увеличилось и равно 40351. Удаляю эти дубликаты. Если позже придется в рамках исправления возможных аномалий и выбросов заменять их на какие либо значения для определенных колонок - то процедуру проверки и удаления дубликатов на этом же множестве аттрибутов надо повторить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Количество дубликатов: df_cars: {df_cars.duplicated(subset=df_cars.columns.difference(list_for_duplicates)).sum()}')\n",
    "df_cars = df_cars.drop_duplicates(subset=df_cars.columns.difference(list_for_duplicates))\n",
    "print(f'Количество дубликатов: df_cars: {df_cars.duplicated(subset=df_cars.columns.difference(list_for_duplicates)).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследовательский анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sub_plot_hist_boxplot(df, col_list, title):\n",
    "    for col in col_list:\n",
    "        if col == 'id':\n",
    "            continue\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "        df[col].plot(kind=\"hist\", title=col, figsize=(10, 5), ax = axes[0])\n",
    "        sns.boxplot(df[col], ax = axes[1])\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "def plot_pie_plot_for_columns(df, col_list, title):\n",
    "    for col in col_list:\n",
    "        df[col].value_counts().plot(kind='pie', labels=None, label='', autopct='%1.0f%%', legend=True, figsize=(5,5), title=col);\n",
    "        plt.title(f'{title} for {col}')\n",
    "        plt.show()\n",
    "\n",
    "def plot_bar_plot_for_columns(df, col_list, title, normalizer = 1):\n",
    "    for col in col_list:\n",
    "        print(col)\n",
    "        ax = df[col].value_counts().plot(kind='bar',  label='',  figsize=(5,5), title=col);\n",
    "        plt.title(f'{title} for {col}')\n",
    "        if normalizer != 1:\n",
    "          vals = ax.get_yticks()\n",
    "          ax.set_yticklabels(['{:,.0%}'.format(x / normalizer) for x in vals])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посмотрим на значения колонок с timestamps и RegistrationYear - как они сочетаются друг с другом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из анализа графиков и вывода метода describe() для колонок *'DateCrawled', 'DateCreated', 'LastSeen'* видно, что данные по этим трем колонкам в основном сосредоточены в диапазоне 2016-01 - 2016-04. Выше правой границы значений нет, ниже левой границы есть небольшое количество выбросов до 2014-04\n",
    "\n",
    "Проанализировав график и вывода метода decribe() атрибуту RegistrationYear - видно что его среднее и медиана находятся в районе 2003-2004 гг, но имеют место выбросы как в большую сторону вплоть до 9999, так и в меньшую сторону вплоть до 1000. Так как нет возможности выяснить как собирались эти данные и выяснить причину этих выбросов - то необходимо сначала избавиться от слишком явных выбросов - так как я не вижу тут больше других вариантов как и чем их можно было заменить. Так как max Значение аттрибута *DateCreated*  = 2016-04-07 то наибольшее валидное значение аттрибута RegistrationYear это 2016 г так как при создании анкеты нельзя указать автомобиль с годом регистрации в будущем (если это не ошибка ввода). Таким образом верхняя граница отсечки по аттрибуту RegistrationYear это 2016. Что касается нижней границы отсечки то возьмем ее условно равной 1950 годом - автомобили за более ранние даты от 1950 г до момента начала автомобильной эры (1900 г) представляют собой уже очень дорогие раритеты, ну а за период от 1000 до 1900 гг никаких автомобилей не было. В данном допущении я исхожу из того, что аттрибут RegistrationYear важен для работы модели, так как он на мой взгляд, является признаком, по которому можно охарактеризовать тот или иной автомобиль и мы не можем просто исключить его из входных признаков для модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.loc[:,['DateCrawled', 'DateCreated', 'LastSeen']].plot.line();\n",
    "display(df_cars.loc[:,['DateCrawled', 'DateCreated', 'LastSeen']].describe())\n",
    "plot_sub_plot_hist_boxplot(df_cars, ['RegistrationYear'],'')\n",
    "display(df_cars.loc[:,['RegistrationYear']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После отсечки гистограмма RegistrationYear приобрела боллее читаемый вид, графики для аттрибутов 'DateCrawled', 'DateCreated', 'LastSeen' особо не изменились. Далее нужно провести проверку на соответствие даты из аттрибутов DateCreated и RegistrationYear, при этом DateCreated приведенный к году должен быть больше или равен RegistrationYear, другими словами нельзя при создании анкеты указать RegistrationYear в будущем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_ryear_cut = df_cars[(df_cars['RegistrationYear'] <= 2016) & (df_cars['RegistrationYear'] >= 1950)]\n",
    "df_cars_ryear_cut.info()\n",
    "df_cars_ryear_cut.loc[:,['DateCrawled', 'DateCreated', 'LastSeen']].plot.line();\n",
    "display(df_cars_ryear_cut.loc[:,['DateCrawled', 'DateCreated', 'LastSeen']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут я вижу, что записей для которых не выполняется указанное выше условие в датафрейме нет - то есть даты  DateCreated и RegistrationYear согласованы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_ryear_cut['CreatedYear'] = df_cars_ryear_cut['DateCreated'].dt.strftime('%Y')\n",
    "df_cars_ryear_cut['CreatedYear'] = df_cars_ryear_cut['CreatedYear'].astype('int64')\n",
    "print(df_cars_ryear_cut['Brand'].count())\n",
    "df_cars_ryear_cut_new = df_cars_ryear_cut[df_cars_ryear_cut['CreatedYear'] >= df_cars_ryear_cut['RegistrationYear']]\n",
    "print(df_cars_ryear_cut_new['Brand'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_ryear_cut = df_cars_ryear_cut.drop(['CreatedYear'], axis=1)\n",
    "df_cars_ryear_cut.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sub_plot_hist_boxplot(df_cars_ryear_cut, ['RegistrationYear'],'')\n",
    "display(df_cars_ryear_cut.loc[:,['RegistrationYear']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поменял тип для аттрибутов с object на string. PostalCode и RegistrationMonth также сделал категориальными переменными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_string_col_list = ['RegistrationMonth', 'PostalCode', 'VehicleType', 'Gearbox', 'Model', 'FuelType', 'Repaired']\n",
    "#df_cars.info()\n",
    "df_cars_ryear_cut[int_to_string_col_list] = df_cars_ryear_cut[int_to_string_col_list].astype('string')\n",
    "df_cars_ryear_cut.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее я вывожу статситику по категориальным признакам - 'VehicleType', 'Gearbox', 'Model', 'RegistrationMonth', 'FuelType', 'Brand', 'Repaired', 'PostalCode' - такие методы как describe, value_counts и bar plot (в bar plot не включил PostalCode так как там очень большое количество уникальных значений и график неинформативен и очень долго строится). Статистика по RegistrationMonth показывает что этот аттрибут принимает значения от 0 до 12 включительно то есть 13 различных значений - а месяцев в году 12. При этом частота повторения каждого месяца примерно одинакова и в связи с этим непонятно как быть с лишним месяцем - то ли брать за начальное значение 0 и тогда лишним будет месяц 12, то ли отсчет вести от месяца 1 и тогда лишним будет месяц 0 и также непонятно что делать с этим лишним месяцем - заменять его на моду множества - так частота примерно одинакова. Отбросить данные с \"лишним\" месяцем тоже нельзя - так как непонятно какой месяц считать лишним. Поскольку у меня нет информации с чем связана подобная ошибка ввода и как ее надо исправлять - я предлагаю оставить эту ситуаци как есть и ничего с ней не делать. В связи с чем в предсказании модели по аттрибуту Month будет заложена некая погрешность - можно в будущем попробовать удалить этот аттрибут и посмореть как это оразится на метрике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = ['VehicleType', 'Gearbox', 'Model', 'RegistrationMonth', 'FuelType', 'Brand', 'Repaired', 'PostalCode']\n",
    "display(df_cars_ryear_cut.loc[:,cat_list].describe())\n",
    "for c in cat_list:\n",
    "    display(df_cars_ryear_cut[c].value_counts())\n",
    "\n",
    "plot_bar_plot_for_columns(df_cars_ryear_cut, ['VehicleType', 'Gearbox', 'Model', 'RegistrationMonth', 'FuelType', 'Brand', 'Repaired'], \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ гистограмм числовых аттрибутов 'Power', 'Kilometer' показал, что:\n",
    "- аттрибут Power варьируется в диапазоне от 0 до 20000 л.c. Величина 0 это очевидно ошибочное значение (и ряд значений от 0 до некоего минимального 50 л.c. также ошибочны), но и  значения свыше 1000 л.c. также являются ошибочными - 1000 л.c. это мощность гоночного болида. Поэтому я предлагаю сделать отсечку по этому аттрибуту по диапазону 50; 1000 так как я не знаю как вводились эти данные и с чем может связана такая ошибка\n",
    "- аттрибут Kilometer принимает min и max значения равными 5000 и 150000 что кажется мне вполне валидными значениями для пробега"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = ['Power', 'Kilometer']\n",
    "plot_sub_plot_hist_boxplot(df_cars_ryear_cut, num_list, '')\n",
    "display(df_cars_ryear_cut.loc[:,num_list].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Графики для Power после обрезки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_ryear_cut_power = df_cars_ryear_cut[(df_cars_ryear_cut['Power'] <= 1000) & (df_cars_ryear_cut['Power'] >= 50)]\n",
    "plot_sub_plot_hist_boxplot(df_cars_ryear_cut_power, num_list, '')\n",
    "display(df_cars_ryear_cut_power.loc[:,num_list].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter pair plot для числовых аттрибутов 'RegistrationYear', 'Kilometer', 'Power' не показал каких либо аномалий и выраженной линейной зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_col_list = ['RegistrationYear', 'Kilometer', 'Power']\n",
    "g = sns.pairplot(data = df_cars_ryear_cut_power, vars = scatter_col_list, height=3)\n",
    "for ax in g.axes.flat:\n",
    "    ax.tick_params(\"x\", labelrotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убираю из датафрейма df_cars_ryear_cut_power колонки 'DateCrawled', 'DateCreated', 'LastSeen' которые не нужны для моделирования так как представляют собой справочную информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_ryear_cut_power = df_cars_ryear_cut_power.drop(['DateCrawled', 'DateCreated', 'LastSeen'], axis=1)\n",
    "df_cars_ryear_cut_power.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фик матрица была построена по всем аттрибутам датафрейма df_cars_ryear_cut_power за вычетом целевого аттрибута Price. Из анализа этой матрицы я вижу:\n",
    "- корреляция между аттрибутами Model и Brand = 1. Это объяснимо так как Модель в данном случае является Брендом и наоборот - между ними взаимно однозначное соответствие (возможно отношение один ко многим для связи Brand -> Model)\n",
    "- корреляция между Model и VehicleType довольно высока = 0.91\n",
    "- корреляция между Brand и VehicleType ниже и = 0.62\n",
    "\n",
    "В связи с этим предлагается убрать из входных аттрибутов Model так как он имеет высокую корреляцию с двуми другими аттрибутами Brand и VehicleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phik_overview = phik_matrix(df_cars_ryear_cut_power[df_cars_ryear_cut_power.columns.difference(['Price'])], interval_cols=scatter_col_list)\n",
    "\n",
    "display(phik_overview)\n",
    "plot_correlation_matrix(\n",
    "    phik_overview.values,\n",
    "    x_labels=phik_overview.columns,\n",
    "    y_labels=phik_overview.index,\n",
    "    vmin=0, vmax=1, color_map='Greens',\n",
    "    title=r'correlation $\\phi_K$',\n",
    "    fontsize_factor=1.2,\n",
    "    figsize=(14, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_ryear_cut_power = df_cars_ryear_cut_power.drop(['Model'], axis=1)\n",
    "df_cars_ryear_cut_power.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После удаления аттрибута Model фик матрица выглядит лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phik_overview = phik_matrix(df_cars_ryear_cut_power[df_cars_ryear_cut_power.columns.difference(['Price'])], interval_cols=scatter_col_list)\n",
    "\n",
    "display(phik_overview)\n",
    "plot_correlation_matrix(\n",
    "    phik_overview.values,\n",
    "    x_labels=phik_overview.columns,\n",
    "    y_labels=phik_overview.index,\n",
    "    vmin=0, vmax=1, color_map='Greens',\n",
    "    title=r'correlation $\\phi_K$',\n",
    "    fontsize_factor=1.2,\n",
    "    figsize=(14, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных и обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделяем датафреймы для входных и целевого признака, производим разбиение на тренировочную и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cars_ryear_cut_power.drop(['Price'], axis=1)\n",
    "y = df_cars_ryear_cut_power['Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем модель CatBoostRegressor с параметрами iterations=10,learning_rate=1,depth=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['RegistrationMonth', 'VehicleType', 'Gearbox', 'FuelType', 'Brand', 'Repaired', 'PostalCode']\n",
    "model = CatBoostRegressor(iterations=10,learning_rate=1,depth=2)\n",
    "model.fit(X_train, y_train, cat_features=cat_columns)\n",
    "preds_cbr = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовим данные для LGBMRegressor (с заменой типа string на category) и строим модель LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lgbm_train = X_train.copy()\n",
    "X_lgbm_test = X_test.copy()\n",
    "\n",
    "def LGBMdfCreator(df):\n",
    "    for c in df.columns:\n",
    "        col_type = df[c].dtype\n",
    "        if col_type == 'string':\n",
    "            df[c] = df[c].astype('category')\n",
    "\n",
    "LGBMdfCreator(X_lgbm_train)\n",
    "LGBMdfCreator(X_lgbm_test)\n",
    "\n",
    "X_lgbm_train.info()\n",
    "X_lgbm_test.info()\n",
    "\n",
    "gbm2 = LGBMRegressor(objective='rmse', random_state=RANDOM_STATE, early_stopping_rounds = 5, n_estimators=10000)\n",
    "gbm2.fit(X_lgbm_train,  y_train, eval_set=[(X_lgbm_test, y_test)], eval_metric='rmse')\n",
    "gbm2eval = gbm2.evals_result_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее формируем списки для энкодеров и скейлеров OneHotEncoder, OrdinalEncoder и MinMaxScaler и формируем ColumnTransformer для этих скейлеров для использования в пайплайне для non-boost модели DecisionTreeRegressor. Певоначальный прогон модели на основном датафрейме выдал ошибку **Unable to allocate 11.9 GiB for an array with shape (196129, 8113) and data type float64** что было связано с наличием категориального признака *PostalCode* c большим количеством категорий. Я считаю этот признак значимым для модели и две предыдущие boost модели успешно с ним справились и выдали метрику в рамках нужного диапазона. Но для успешной работы данной модели я дропну этот признак. Кроме того - в текущей версии sklearn = 0.24.1 нет метрики root_mean_squared_error и я ее реализовал через mean_squared_error (можно было проапгрейдить sklearn до максимальной версии но я не уверен что это не потянет за собой другие библиотеки и это надо делать централизовано в среде Практикума)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['PostalCode'], axis=1)\n",
    "X_test = X_test.drop(['PostalCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_columns = list(X_train.select_dtypes(include=np.number))\n",
    "ord_columns = ['RegistrationMonth']\n",
    "#ohe_columns = ['VehicleType', 'Gearbox', 'FuelType', 'Brand', 'Repaired', 'PostalCode']\n",
    "ohe_columns = ['VehicleType', 'Gearbox', 'FuelType', 'Brand', 'Repaired']\n",
    "month_order_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "\n",
    "ohe_pipe = Pipeline(\n",
    "    [\n",
    "     ('ohe', OneHotEncoder(drop='first', handle_unknown='error', sparse=False))\n",
    "    ]\n",
    "    )\n",
    "\n",
    "ord_pipe = Pipeline(\n",
    "    [\n",
    "     ('ohe', OrdinalEncoder(categories=[month_order_list]))\n",
    "    ]\n",
    "    )\n",
    "\n",
    "data_preprocessor = ColumnTransformer(\n",
    "    [('ohe', ohe_pipe, ohe_columns),\n",
    "     ('ord', ord_pipe, ord_columns),\n",
    "     ('num', MinMaxScaler(), num_columns)\n",
    "    ], \n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pipe_final = Pipeline([\n",
    "    ('preprocessor', data_preprocessor),\n",
    "    ('models', DecisionTreeRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'models': [DecisionTreeRegressor(random_state=RANDOM_STATE)],\n",
    "        'models__max_depth': range(2, 6),\n",
    "        'models__max_features': range(2, 6)  \n",
    "    },\n",
    "]\n",
    "\n",
    "mse = make_scorer(mean_squared_error,greater_is_better=False)\n",
    "grid_search = GridSearchCV(\n",
    "    pipe_final, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring=mse,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "result = pd.DataFrame(grid_search.cv_results_)\n",
    "display(result[\n",
    "    ['rank_test_score', 'param_models', 'mean_test_score','params']\n",
    "].sort_values('rank_test_score')) \n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    " \n",
    "print ('Лучшая модель и её параметры:\\n', grid_search.best_estimator_)\n",
    "print ('Метрика RMSE лучшей модели на тренировочной выборке:', sqrt(-grid_search.best_score_))\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse_test = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print (\"Метрика RMSE лучшей модели на тестовой выборке:\", rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод таблицы с результатами по трем моделям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame({'Model':['CatBoostRegressor', 'LGBMRegressor', 'DecisionTreeRegressor'], 'RMSE':['2330', '1799', '3492'], 'time':['5', '5', '33']}) \n",
    "display(df_models)\n",
    "\n",
    "pred_gbm = gbm2.predict(X_lgbm_test)\n",
    "rmse_test_catboost = sqrt(mean_squared_error(y_test, pred_gbm))\n",
    "print (\"Метрика RMSE лучшей модели LGBMRegressor на тестовой выборке:\", rmse_test_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках проекта Определение стоимости автомобилей были проведены следующие действия:\n",
    "- загружены данные из источника данных *https://code.s3.yandex.net/datasets/autos.csv*\n",
    "- проведен анализ данных на пропуски, найденные пропуски в категориальных колонках были заменены на моду по данному аттрибуту\n",
    "- были определены колонки, которые не должны участвовать в работе модели и такие колонки были дропнуты\n",
    "- проведен исследовательский анализ данных с проверкой на аномалии и выбросы, в соответствии с этим ряд данных был удален\n",
    "- была проведена проверка на дубликаты только в рамках входных аттрибутов модели и найденный дубликаты были удалены \n",
    "- была построена фик матрица, на основани которой была удалена колонка, находящаяся в линейной зависимости с двумя другими колонками\n",
    "- были построены три модели (данные по ним в таблице выше):\n",
    "  - CatBoostRegressor\n",
    "  - LGBMRegressor\n",
    "  - DecisionTreeRegressor\n",
    "- на основании полученных данных и условий сдачи проекта лучшей моделью балы признана модель LGBMRegressor с целевой метрикой RMSE = 1799 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
